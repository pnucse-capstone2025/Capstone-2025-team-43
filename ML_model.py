#!/usr/bin/env python3
import os
import glob
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torch.amp import autocast, GradScaler
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.utils.class_weight import compute_class_weight
from sklearn.model_selection import StratifiedShuffleSplit # StratifiedShuffleSplit ì¶”ê°€
from tqdm import tqdm
import warnings
from pathlib import Path
import argparse

warnings.filterwarnings('ignore')

# ====================== í•˜ì´í¼íŒŒë¼ë¯¸í„° ======================
BATCH = 256              # ë°°ì¹˜ í¬ê¸°
EPOCHS = 100             # ì „ì²´ ì—í­ ìˆ˜
HIDDEN_DIM1 = 64         # ì²« ë²ˆì§¸ LSTM ë ˆì´ì–´ ì€ë‹‰ ë…¸ë“œ ìˆ˜
HIDDEN_DIM2 = 16         # ë‘ ë²ˆì§¸ LSTM ë ˆì´ì–´ ì€ë‹‰ ë…¸ë“œ ìˆ˜
NUM_CLASSES = 4          # Hotness ë¶„ë¥˜ í´ë˜ìŠ¤ ìˆ˜
LEARNING_RATE = 0.03   # í•™ìŠµë¥ 
USE_AMP = True           # AMP (í˜¼í•© ì •ë°€ë„) ì‚¬ìš© ì—¬ë¶€
PATIENCE = 10            # Early Stopping patience ê¸°ì¤€
DROPOUT_RATE = 0.2       # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ (ê³¼ì í•© ë°©ì§€ìš©)

# ====================== ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ ======================
CHECK_DIR = "ckpt_np"    # ì²´í¬í¬ì¸íŠ¸ ì„ì‹œ ì €ì¥ í´ë”
OUT_DIR = "outputs"      # ìµœì¢… ëª¨ë¸ ê²°ê³¼ë¬¼ ì„ì‹œ ì €ì¥ í´ë”

os.makedirs(CHECK_DIR, exist_ok=True)
os.makedirs(OUT_DIR, exist_ok=True)

# ====================== ìµœì¢… ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ======================
OUTPUT_MODEL_BASE_DIR = "/home/teamssdeep/ssd_project/models"
os.makedirs(OUTPUT_MODEL_BASE_DIR, exist_ok=True)

# ====================== ë°ì´í„°ì…‹ ë˜í¼ ======================
class NumpyTrace(Dataset):
    """ë„˜íŒŒì´ í˜•ì‹ì˜ (X, y) ë°ì´í„°ë¥¼ PyTorch Datasetìœ¼ë¡œ ë˜í•‘"""
    def __init__(self, x, y):
        self.x = torch.tensor(x, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)
    def __len__(self):
        return len(self.x)
    def __getitem__(self, i):
        return self.x[i], self.y[i]

# ================= LSTM ë¶„ë¥˜ê¸°(ëª¨ë¸ ì •ì˜) =================
class StackedLSTMClassifier(nn.Module):
    """4â†’64â†’16â†’4 êµ¬ì¡°ì˜ Stacked-LSTM (ë“œë¡­ì•„ì›ƒ ì¶”ê°€)"""
    def __init__(self, input_dim=4, hidden_dim1=HIDDEN_DIM1, hidden_dim2=HIDDEN_DIM2,
                 num_classes=NUM_CLASSES, dropout_rate=DROPOUT_RATE):
        super().__init__()
        self.lstm1 = nn.LSTM(input_dim, hidden_dim1, num_layers=1,
                             batch_first=True)
        self.lstm2 = nn.LSTM(hidden_dim1, hidden_dim2, num_layers=1,
                             batch_first=True)
        self.dropout = nn.Dropout(dropout_rate) # ë“œë¡­ì•„ì›ƒ ë ˆì´ì–´ ì¶”ê°€
        self.fc = nn.Linear(hidden_dim2, num_classes)
    def forward(self, x):
        out1, _ = self.lstm1(x)
        out2, _ = self.lstm2(out1)
        out = out2[:, -1, :]
        out = self.dropout(out) # ë“œë¡­ì•„ì›ƒ ì ìš©
        out = self.fc(out)
        return out

# ============== í´ë˜ìŠ¤ ë¶ˆê· í˜• ê°€ì¤‘ì¹˜ ê³„ì‚° í•¨ìˆ˜ =============
def compute_class_weights(y):
    """í´ë˜ìŠ¤ë³„ ë°ì´í„° ìˆ˜ì˜ ë¶ˆê· í˜•ì„ ë³´ì •í•˜ê¸° ìœ„í•œ sample weight ê³„ì‚°"""
    unique_classes = np.unique(y)
    weights = compute_class_weight('balanced', classes=unique_classes, y=y)
    class_weights = dict(zip(unique_classes, weights))
    print(f"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weights}")
    return class_weights

# === ë°ì´í„°ì…‹ ì…‹ ë¶„í•  í•¨ìˆ˜ (ê³„ì¸µì  ìƒ˜í”Œë§) ===
def split_data_stratified(x, y, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):
    """
    ë°ì´í„°ë¥¼ ê³„ì¸µì  ìƒ˜í”Œë§ì„ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì…‹ìœ¼ë¡œ ë¶„í• 
    ê¸°ë³¸ì€ 6:2:2 ë¹„ìœ¨. ê° ì„¸íŠ¸ì— ëª¨ë“  í´ë˜ìŠ¤ê°€ ë¹„ìœ¨ì— ë§ì¶° í¬í•¨ë˜ë„ë¡ ë³´ì¥í•¨.
    """
    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6
    
    # í›ˆë ¨ + ê²€ì¦ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¨¼ì € ë¶„í• 
    split1 = StratifiedShuffleSplit(n_splits=1, test_size=test_ratio, random_state=42)
    for train_val_index, test_index in split1.split(x, y):
        x_train_val, x_test = x[train_val_index], x[test_index]
        y_train_val, y_test = y[train_val_index], y[test_index]
    
    # í›ˆë ¨ ì„¸íŠ¸ì™€ ê²€ì¦ ì„¸íŠ¸ë¡œ ë‹¤ì‹œ ë¶„í• 
    # train_val_sizeì— ëŒ€í•œ ê²€ì¦ ì„¸íŠ¸ ë¹„ìœ¨ ê³„ì‚°
    val_size_in_train_val = val_ratio / (train_ratio + val_ratio)
    split2 = StratifiedShuffleSplit(n_splits=1, test_size=val_size_in_train_val, random_state=42)
    for train_index, val_index in split2.split(x_train_val, y_train_val):
        x_train, x_val = x_train_val[train_index], x_train_val[val_index]
        y_train, y_val = y_train_val[train_index], y_train_val[val_index]
    
    print(f"ë°ì´í„° ë¶„í•  (ê³„ì¸µì  ìƒ˜í”Œë§): í›ˆë ¨={len(x_train):,}, ê²€ì¦={len(x_val):,}, í…ŒìŠ¤íŠ¸={len(x_test):,}")
    
    return x_train, y_train, x_val, y_val, x_test, y_test


# ================ ëª¨ë¸ í‰ê°€ í•¨ìˆ˜ =========================
def evaluate_model(model, dataloader, criterion, device, phase="Test"):
    """ì£¼ì–´ì§„ ë°ì´í„°ì…‹(phase: train/val/test)ì— ëŒ€í•´ ì†ì‹¤ê³¼ ì •í™•ë„ ë°˜í™˜"""
    model.eval()
    total_loss = 0.0
    correct = 0
    total = 0
    all_predictions = []
    all_labels = []
    with torch.no_grad():
        for x_batch, y_batch in dataloader:
            x_batch, y_batch = x_batch.to(device), y_batch.to(device)
            with autocast(device_type="cuda", enabled=USE_AMP):
                outputs = model(x_batch)
                loss = criterion(outputs, y_batch)
            total_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += y_batch.size(0)
            correct += (predicted == y_batch).sum().item()
            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(y_batch.cpu().numpy())
    avg_loss = total_loss / len(dataloader)
    accuracy = 100 * correct / total
    print(f"{phase} ê²°ê³¼: Loss={avg_loss:.4f}, Accuracy={accuracy:.2f}%")
    return avg_loss, accuracy, all_predictions, all_labels

# ============ ì²´í¬í¬ì¸íŠ¸(ì„ì‹œëª¨ë¸) ì €ì¥ ë° ë¡œë“œ ===========
def save_ckpt_rot(path: str, epoch: int, step: int, model: nn.Module, scaler: GradScaler):
    """ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥, ìµœì‹  3ê°œë§Œ ë³´ê´€ í›„ ë‚˜ë¨¸ì§€ ì‚­ì œ"""
    torch.save({"epoch": epoch, "step": step,
                 "model": model.state_dict(),
                 "scaler": scaler.state_dict()},
                 path)
    ckpts = sorted(glob.glob(f"{CHECK_DIR}/*.pt"), key=os.path.getmtime)
    for f in ckpts[:-3]:
        os.remove(f)

def load_ckpt(path: str, model: nn.Module, scaler: GradScaler):
    ck = torch.load(path, map_location="cpu")
    model.load_state_dict(ck["model"])
    scaler.load_state_dict(ck["scaler"])
    return ck["epoch"], ck["step"]

# ================ í•™ìŠµ ë©”ì¸ í•¨ìˆ˜ ==========================
def train(x_path: str, y_path: str, model_output_name: str, resume: str = None):
    print("=== SSD í˜ì´ì§€ Hotness ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ===")
    
    # --- ë°ì´í„° ë¡œë”© ë° ì •ë³´ ì¶œë ¥ ---
    if not os.path.exists(x_path) or not os.path.exists(y_path):
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {x_path} ë˜ëŠ” {y_path}")
        return
    x = np.load(x_path)
    y = np.load(y_path)
    print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: X={x.shape}, y={y.shape}")
    print(f"ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´: {x.shape[1]}, íŠ¹ì„± ìˆ˜: {x.shape[2]}")

    # ===== í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥ ì¶”ê°€ =====
    print(f"\n=== í•™ìŠµ íŒŒë¼ë¯¸í„° ===")
    print(f"BATCH: {BATCH}")
    print(f"EPOCHS: {EPOCHS}")
    print(f"HIDDEN_DIM1: {HIDDEN_DIM1}")
    print(f"HIDDEN_DIM2: {HIDDEN_DIM2}")
    print(f"NUM_CLASSES: {NUM_CLASSES}")
    print(f"LEARNING_RATE: {LEARNING_RATE}")
    print(f"USE_AMP: {USE_AMP}")
    print(f"PATIENCE: {PATIENCE}")
    print(f"DROPOUT_RATE: {DROPOUT_RATE}")
    print("") # ê°€ë…ì„±ì„ ìœ„í•œ ë¹ˆ ì¤„ ì¶”ê°€
    # ============================================

    unique_labels, counts = np.unique(y, return_counts=True)
    print(f"\n=== í´ë˜ìŠ¤ ë¶„í¬ ===")
    hotness_labels = ['Cold(0)', 'Medium(1)', 'Warm(2)', 'Hot(3)']
    for label, count in zip(unique_labels, counts):
        if label < len(hotness_labels):
            percentage = (count / len(y)) * 100
            print(f"{hotness_labels[label]}: {count:,}ê°œ ({percentage:.1f}%)")
    
    # --- ë°ì´í„°ì…‹ ë¶„í•  ---
    # ê³„ì¸µì  ìƒ˜í”Œë§ì„ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œë¡œ ë³€ê²½
    x_train, y_train, x_val, y_val, x_test, y_test = split_data_stratified(x, y, 0.6, 0.2, 0.2)
    
    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    class_weights_dict = compute_class_weights(y_train)
    class_weights = torch.FloatTensor([class_weights_dict.get(i, 1.0) for i in range(NUM_CLASSES)])
    
    # --- ë°ì´í„°ë¡œë” ìƒì„± ---
    train_dataset = NumpyTrace(x_train, y_train)
    val_dataset = NumpyTrace(x_val, y_val)
    test_dataset = NumpyTrace(x_test, y_test)
    nw = min(4, os.cpu_count())
    train_loader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True, # í›ˆë ¨ ë°ì´í„°ë§Œ shuffle=True
                              num_workers=nw, pin_memory=True, persistent_workers=nw > 0)
    val_loader = DataLoader(val_dataset, batch_size=BATCH, shuffle=False,
                            num_workers=nw, pin_memory=True, persistent_workers=nw > 0)
    test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=False,
                             num_workers=nw, pin_memory=True, persistent_workers=nw > 0)
    
    # --- ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ìµœì í™”ê¸° ì„¤ì • ---
    dev = "cuda" if torch.cuda.is_available() else "cpu"
    model = StackedLSTMClassifier(input_dim=x.shape[2]).to(dev)
    class_weights = class_weights.to(dev)
    opt = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=5)
    lossf = nn.CrossEntropyLoss(weight=class_weights)
    scaler = GradScaler(enabled=USE_AMP)
    print(f"\n=== ëª¨ë¸ êµ¬ì¡° ===")
    print(f"LSTM1: {x.shape[2]} â†’ {HIDDEN_DIM1}")
    print(f"LSTM2: {HIDDEN_DIM1} â†’ {HIDDEN_DIM2}")
    print(f"FC: {HIDDEN_DIM2} â†’ {NUM_CLASSES}")
    print(f"ì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")
    print(f"Device: {dev}")
    
    # --- í•™ìŠµ/ë³µêµ¬ ì¤€ë¹„ ---
    start_ep, gstep = 1, 0
    if resume and os.path.exists(resume):
        start_ep, gstep = load_ckpt(resume, model, scaler)
        print(f"[RESUME] epoch {start_ep}, step {gstep}")
    best_val_loss = float('inf')
    patience_counter = 0
    
    # ============= í•™ìŠµ ë£¨í”„ =============
    print(f"\n=== í•™ìŠµ ì‹œì‘ ===")
    for ep in range(start_ep, EPOCHS + 1):
        model.train()
        total_loss, total, correct = 0, 0, 0
        pbar = tqdm(train_loader, desc=f"Epoch {ep}/{EPOCHS}")
        for batch_idx, (xb, yb) in enumerate(pbar):
            gstep += 1
            xb, yb = xb.to(dev), yb.to(dev)
            opt.zero_grad()
            # AMP(í˜¼í•©ì •ë°€ë„) ì‚¬ìš©
            with autocast(device_type="cuda", enabled=USE_AMP):
                logits = model(xb)
                loss = lossf(logits, yb)
            scaler.scale(loss).backward()
            scaler.unscale_(opt)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            scaler.step(opt)
            scaler.update()
            total_loss += loss.item() * xb.size(0)
            preds = logits.argmax(dim=1)
            correct += (preds == yb).sum().item()
            total += xb.size(0)
            if batch_idx % 100 == 0:
                acc = correct / total
                pbar.set_postfix(loss=f"{loss.item():.3f}", acc=f"{acc:.3f}",
                                 lr=f"{opt.param_groups[0]['lr']:.6f}")
            if gstep % 5000 == 0:
                fname = f"{CHECK_DIR}/ep{ep}_step{gstep}.pt"
                save_ckpt_rot(fname, ep, gstep, model, scaler)
        train_acc = correct / total
        train_loss = total_loss / total

        # --- ê²€ì¦ ì„±ëŠ¥ í‰ê°€ ---
        val_loss, val_acc, _, _ = evaluate_model(model, val_loader, lossf, dev, "Validation")
        scheduler.step(val_loss)
        print(f"Epoch {ep}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, "
              f"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}, "
              f"LR={opt.param_groups[0]['lr']:.6f}")
        # --- Early Stopping ---
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            # ì„ì‹œ ìµœì  ëª¨ë¸ ì €ì¥ (OUT_DIRì— ì €ì¥)
            torch.save({
                'model_state_dict': model.state_dict(),
                'epoch': ep,
                'val_loss': val_loss,
                'val_acc': val_acc,
                'input_dim': x.shape[2],
                'hidden_dim1': HIDDEN_DIM1,
                'hidden_dim2': HIDDEN_DIM2,
                'num_classes': NUM_CLASSES
            }, f"{OUT_DIR}/best_ssd_hotness_model.pth")
            print(f"âœ“ ìµœì  ëª¨ë¸ ì €ì¥: Val Acc={val_acc:.2f}%")
        else:
            patience_counter += 1
            if patience_counter >= PATIENCE:
                print(f"ì¡°ê¸° ì¢…ë£Œ at epoch {ep} (patience={PATIENCE})")
                break

    # ============= ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€ ë° ëª¨ë¸ ì €ì¥ =============
    print(f"\n=== ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€ ===")
    # OUT_DIRì— ì €ì¥ëœ ì„ì‹œ ìµœì  ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ìµœì¢… í…ŒìŠ¤íŠ¸
    best_model_path = f"{OUT_DIR}/best_ssd_hotness_model.pth"
    if os.path.exists(best_model_path):
        checkpoint = torch.load(best_model_path)
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"ìµœì  ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Epoch {checkpoint['epoch']})")
    else:
        print(f"ê²½ê³ : ìµœì  ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ì—í­ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.")

    test_loss, test_acc, test_predictions, test_labels = evaluate_model(
        model, test_loader, lossf, dev, "Test")
        
    # --- classification_report í˜¸ì¶œ ---
    print(f"\n=== ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸ ===")
    target_names = ['Cold(0)', 'Medium(1)', 'Warm(2)', 'Hot(3)']
    unique_labels = np.unique(test_labels)
    # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” ë¼ë²¨ê³¼ ê·¸ì— í•´ë‹¹í•˜ëŠ” ì´ë¦„ë§Œ ì‚¬ìš©
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” ê³ ìœ  ë¼ë²¨: {unique_labels}")
    print(f"ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•´ ì‚¬ìš©ëœ ì´ë¦„: {[target_names[i] for i in unique_labels]}")
    print(classification_report(test_labels, test_predictions, target_names=[target_names[i] for i in unique_labels], labels=unique_labels))
    print(f"\n=== í˜¼ë™ í–‰ë ¬ ===")
    print(confusion_matrix(test_labels, test_predictions, labels=unique_labels))
    # ---------------------------------------------

    # ìµœì¢… ëª¨ë¸ ì €ì¥ (OUTPUT_MODEL_BASE_DIRì— ì €ì¥)
    model_save_path = os.path.join(OUTPUT_MODEL_BASE_DIR, f"{model_output_name}.pth")
    torch.save(model.state_dict(), model_save_path)
    print(f"\nâœ… ìµœì¢… ëª¨ë¸ ì €ì¥: {model_save_path}")
    print(f"\nğŸ‰ í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.2f}%")
    print(f"ğŸ“ ëª¨ë¸ íŒŒì¼: {model_save_path}")
    print(f"ğŸ“‹ ëª¨ë¸ êµ¬ì¡°: 4â†’64â†’16â†’4")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='SSD Hotness Classification Model Training')
    parser.add_argument('--x_path', type=str,
                        default='/home/teamssdeep/ssd_project/data/npy/X_sa00_page.npy',
                        help='Path to the input X_*.npy file.')
    parser.add_argument('--y_path', type=str,
                        default='/home/teamssdeep/ssd_project/data/npy/y_sa00_page.npy',
                        help='Path to the input y_*.npy file.')
    parser.add_argument('--model_name', type=str,
                        default='sa00_model',
                        help='Name for the output model file (without .pth extension).')
    parser.add_argument('--resume', type=str, default=None,
                        help='Path to a checkpoint to resume training from.')
    parser.add_argument('--log_dir', type=str,
                        default='/home/teamssdeep/ssd_project/logs',
                        help='Directory to save log files.')
    parser.add_argument('--log_name', type=str,
                        default='sa00_model.txt',
                        help='Name for the log file.')

    args = parser.parse_args()

    os.makedirs(args.log_dir, exist_ok=True)
    
    print("SSD Hotness ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ëª¨ë¸ êµ¬ì¡°: 4â†’64â†’16â†’4")

    train(x_path=args.x_path,
          y_path=args.y_path,
          model_output_name=args.model_name,
          resume=args.resume)
